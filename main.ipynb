{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Jupyter Notebooks for implementing the German Traffic Sign Classification CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibt an, ob wir auf einer GPU oder CPU trainieren \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wird unser mean und unser std für die Normalisierung der Bilder berechnet\n",
    "# dataset = ImageFolder(\"GTSRB\\Final_Training\\Images\", transform=transforms.ToTensor())\n",
    "transform_mean_std = transforms.Compose([\n",
    "    transforms.Resize((35, 35)),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = ImageFolder(\"C:/Users/v814u63/Documents/Uni/5. Semester/XAI/images/train_images\", transform=transform_mean_std)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "mean = 0.\n",
    "std = 0.\n",
    "total_images_count = 0\n",
    "\n",
    "for images, _ in loader:\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    total_images_count += batch_samples\n",
    "\n",
    "mean /= total_images_count\n",
    "std /= total_images_count\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform definieren zum Einlesen der Test- und Trainingsdaten\n",
    "img_size = 35 \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean.tolist(), std.tolist()) \n",
    "])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomRotation(20),  # Zufällige Rotation um ±20 Grad\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),  # Zufälliges Zuschneiden und Skalieren\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # Helligkeit und Farbvariation\n",
    "    transforms.RandomHorizontalFlip(),  # Zufälliges horizontales Spiegeln\n",
    "    transforms.ToTensor(),  # Umwandlung zu einem Tensor\n",
    "    transforms.Normalize(mean.tolist(), std.tolist())  # Normalisierung\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Daten und anschließende Ausgabe eines Bildes inkl. Label zur überprüfung\n",
    "train_dataset = ImageFolder(root='C:/Users/v814u63/Documents/Uni/5. Semester/XAI/images/train_images', transform=transform)\n",
    "train_transforms_dataset = ImageFolder(root='C:/Users/v814u63/Documents/Uni/5. Semester/XAI/images/train_images', transform=train_transforms)\n",
    "\n",
    "test_dataset = ImageFolder(root='C:/Users/v814u63/Documents/Uni/5. Semester/XAI/images/test_images', transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "test_loader = DataLoader(test_dataset, batch_size= batch_size, shuffle=True)\n",
    "train_transforms_loader = DataLoader(train_transforms_dataset, batch_size= batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n",
    "num_classes = 43\n",
    "# --------- Testing ---------\n",
    "img, label = train_dataset[4000]\n",
    "label_string = test_dataset.classes[label]\n",
    "print(\"Label:\", label_string)\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "#print(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=4, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=4, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=4, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer5 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=4, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.max_pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Dynamische Berechnung der FC-Eingabegröße\n",
    "        self.flatten = nn.Flatten()\n",
    "        # dummy_input = torch.zeros(batch_size, 3, image_size, image_size)  # Dummy-Eingabe mit typischer Größe (z.B. 224x224)\n",
    "        # fc_input_size = self._get_fc_input_size(dummy_input)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc6 = nn.Linear(128, 512)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(512, 256)\n",
    "        self.relu7 = nn.ReLU()\n",
    "\n",
    "        self.dropout8 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(256, 128)\n",
    "        self.relu8 = nn.ReLU()\n",
    "\n",
    "        self.fc9 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_fc_input_size(self, dummy_input):\n",
    "        \"\"\"Hilfsfunktion, um die Eingabegröße für die Fully Connected Layers zu berechnen.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = self.conv_layer1(dummy_input)\n",
    "            x = self.relu1(x)\n",
    "            x = self.max_pool1(x)\n",
    "\n",
    "            x = self.conv_layer2(x)\n",
    "            x = self.relu2(x)\n",
    "            x = self.max_pool2(x)\n",
    "\n",
    "            x = self.conv_layer3(x)\n",
    "            x = self.relu3(x)\n",
    "\n",
    "            x = self.conv_layer4(x)\n",
    "            x = self.relu4(x)\n",
    "\n",
    "            x = self.conv_layer5(x)\n",
    "            x = self.relu5(x)\n",
    "            x = self.max_pool5(x)\n",
    "\n",
    "            x = self.flatten(x)  # Flatten the output\n",
    "        return x.size(1)  # Gib die Anzahl der Features zurück\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.max_pool1(out)\n",
    "\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.max_pool2(out)\n",
    "\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.max_pool5(out)\n",
    "\n",
    "        out = self.flatten(out)  # Flatten\n",
    "        out = self.dropout6(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.relu6(out)\n",
    "\n",
    "        out = self.dropout7(out)\n",
    "        out = self.fc7(out)\n",
    "        out = self.relu7(out)\n",
    "\n",
    "        out = self.dropout8(out)\n",
    "        out = self.fc8(out)\n",
    "        out = self.relu8(out)\n",
    "\n",
    "        out = self.fc9(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anderes CNN definieren zum Testen\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 750) \n",
    "        self.bn5 = nn.BatchNorm1d(750)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.fc2 = nn.Linear(750, 256)\n",
    "        self.bn6 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(self.bn3(x))\n",
    "        \n",
    "        x = F.relu(self.bn4(self.conv3(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.bn5(self.fc1(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.bn6(self.fc2(x)))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of the model and definition of hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisierung des Modells\n",
    "model = CNN(num_classes).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initiale Lernrate und Optimizer\n",
    "lr = 0.01\n",
    "weight_decay = 0.001\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# ReduceLROnPlateau Scheduler\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, threshold=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # No gradient computation\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the index of the maximum value in the output\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'model/new_cnn_architecture.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with accuracy plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Activation of the Model Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store activations\n",
    "activations = {}\n",
    "\n",
    "# Hook function to capture the outputs\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN(num_classes=43)\n",
    "model.to(device)\n",
    "# Initiale Lernrate und Optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "weight_decay = 0.001\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Register hooks to capture activations from convolutional and fully connected layers\n",
    "model.conv_layer1.register_forward_hook(get_activation('conv_layer1'))\n",
    "model.conv_layer2.register_forward_hook(get_activation('conv_layer2'))\n",
    "model.conv_layer3.register_forward_hook(get_activation('conv_layer3'))\n",
    "model.conv_layer4.register_forward_hook(get_activation('conv_layer4'))\n",
    "model.conv_layer5.register_forward_hook(get_activation('conv_layer5'))\n",
    "\n",
    "# Register hooks for ReLU activations\n",
    "model.relu1.register_forward_hook(get_activation('relu1'))\n",
    "model.relu2.register_forward_hook(get_activation('relu2'))\n",
    "model.relu3.register_forward_hook(get_activation('relu3'))\n",
    "model.relu4.register_forward_hook(get_activation('relu4'))\n",
    "model.relu5.register_forward_hook(get_activation('relu5'))\n",
    "\n",
    "# Register hooks for fully connected layers\n",
    "model.fc6.register_forward_hook(get_activation('fc6'))\n",
    "model.fc7.register_forward_hook(get_activation('fc7'))\n",
    "model.fc8.register_forward_hook(get_activation('fc8'))\n",
    "model.fc9.register_forward_hook(get_activation('fc9'))\n",
    "\n",
    "# Register hooks for ReLU activations in fully connected layers\n",
    "model.relu6.register_forward_hook(get_activation('relu6'))\n",
    "model.relu7.register_forward_hook(get_activation('relu7'))\n",
    "model.relu8.register_forward_hook(get_activation('relu8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Visualization while Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Zusätzliche Listen für neue Visualisierungen\n",
    "last_layer_weights = []\n",
    "pca_results = []\n",
    "\n",
    "num_epochs = 100\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "\n",
    "# Initialize the plots\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Variable für Loader-Wechsel\n",
    "current_loader = train_loader\n",
    "previous_loss = float('inf')\n",
    "switch_epoch = None  # Speichert die Epoche des Loaderswechsels\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0  # Track the loss for the current epoch\n",
    "\n",
    "    for i, (images, labels) in enumerate(current_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = loss_func(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "    # Calculate average loss for the current epoch\n",
    "    avg_loss = running_loss / len(current_loader)\n",
    "\n",
    "    # Accuracy on training and test data\n",
    "    train_accuracy = calculate_accuracy(model, current_loader, device)\n",
    "    test_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Check if loss has increased and Loader hasn't switched yet\n",
    "    if avg_loss > previous_loss and current_loader == train_loader:\n",
    "        print(\"Loss has increased. Switching to train_transforms_loader.\")\n",
    "        current_loader = train_transforms_loader  # Wechsel zu transformiertem Loader\n",
    "        switch_epoch = epoch  # Speichere die Epoche des Wechsels\n",
    "        print(\"Training will continue for exactly 10 epochs after loader switch.\")\n",
    "\n",
    "    # Update the previous loss\n",
    "    previous_loss = avg_loss\n",
    "\n",
    "    # Visualisierung der Gewichte der letzten Schicht (vor dem Output Layer)\n",
    "    last_fc_weights = model.fc9.weight.data.cpu().numpy()  # Anpassen, falls die Schicht anders heißt\n",
    "    last_layer_weights.append(last_fc_weights)\n",
    "\n",
    "    # PCA auf die Output-Vektoren anwenden\n",
    "    with torch.no_grad():\n",
    "        pca = PCA(n_components=2)\n",
    "        outputs_2d = pca.fit_transform(outputs.cpu().numpy())\n",
    "    pca_results.append(outputs_2d)\n",
    "\n",
    "    # Visualisierungen aktualisieren\n",
    "    plt.clf()  # Clear the figure\n",
    "\n",
    "    # Plot 1: Accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(range(1, epoch + 2), train_accuracies, label='Training Accuracy', color='blue')\n",
    "    plt.plot(range(1, epoch + 2), test_accuracies, label='Test Accuracy', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Test Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 2: Loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(range(1, epoch + 2), train_losses, label='Training Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 3: PCA der Outputs\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.scatter(outputs_2d[:, 0], outputs_2d[:, 1], c=labels.cpu().numpy(), cmap='viridis', s=10)\n",
    "    plt.colorbar(label='Class Index')\n",
    "    plt.title('PCA of Output Vectors')\n",
    "    plt.xlabel('PCA Dimension 1')\n",
    "    plt.ylabel('PCA Dimension 2')\n",
    "\n",
    "    # Plot 4: Visualisierung der letzten Layer-Gewichte\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(last_fc_weights, cmap='coolwarm', aspect='auto')\n",
    "    plt.colorbar(label='Weight Value')\n",
    "    plt.title('Weights of Last FC Layer')\n",
    "    plt.xlabel('Neurons')\n",
    "    plt.ylabel('Classes')\n",
    "\n",
    "    if switch_epoch is not None and epoch >= switch_epoch + 10:\n",
    "            print(f\"Stopping training after 10 epochs post-switch at epoch {epoch + 1}.\")\n",
    "            plt.savefig(f'model/optim_loop/RMSprop/train_{train_accuracy}_test_{test_accuracy}.png')\n",
    "            break\n",
    "\n",
    "    # Display the updated plot\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "# Save the model's weights\n",
    "torch.save(model.state_dict(), f'model/gute_modell.pth')\n",
    "torch.save(model.state_dict(), f'model/optim_loop/RMSprop/train_{train_accuracy}_test_{test_accuracy}.pth')\n",
    "\n",
    "# Show the final plot after all epochs\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same with TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Zusätzliche Listen für neue Visualisierungen\n",
    "last_layer_weights = []\n",
    "tsne_results = []\n",
    "\n",
    "num_epochs = 100\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "\n",
    "# Initialize the plots\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Variable für Loader-Wechsel\n",
    "current_loader = train_loader\n",
    "previous_loss = float('inf')\n",
    "switch_epoch = None  # Speichert die Epoche des Loaderswechsels\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0  # Track the loss for the current epoch\n",
    "\n",
    "    for i, (images, labels) in enumerate(current_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = loss_func(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "    # Calculate average loss for the current epoch\n",
    "    avg_loss = running_loss / len(current_loader)\n",
    "\n",
    "    # Accuracy on training and test data\n",
    "    train_accuracy = calculate_accuracy(model, current_loader, device)\n",
    "    test_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Check if loss has increased and Loader hasn't switched yet\n",
    "    if avg_loss > previous_loss and current_loader == train_loader:\n",
    "        print(\"Loss has increased. Switching to train_transforms_loader.\")\n",
    "        current_loader = train_transforms_loader  # Wechsel zu transformiertem Loader\n",
    "        switch_epoch = epoch  # Speichere die Epoche des Wechsels\n",
    "        print(\"Training will continue for exactly 10 epochs after loader switch.\")\n",
    "\n",
    "    # Update the previous loss\n",
    "    previous_loss = avg_loss\n",
    "\n",
    "    # Visualisierung der Gewichte der letzten Schicht (vor dem Output Layer)\n",
    "    last_fc_weights = model.fc9.weight.data.cpu().numpy()  # Anpassen, falls die Schicht anders heißt\n",
    "    last_layer_weights.append(last_fc_weights)\n",
    "\n",
    "    # t-SNE auf die Output-Vektoren anwenden\n",
    "    with torch.no_grad():\n",
    "        tsne = TSNE(n_components=2, perplexity=30, max_iter=1000, random_state=42)\n",
    "        outputs_2d = tsne.fit_transform(outputs.cpu().numpy())\n",
    "    tsne_results.append(outputs_2d)\n",
    "\n",
    "    # Visualisierungen aktualisieren\n",
    "    plt.clf()  # Clear the figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Plot 1: Accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(range(1, epoch + 2), train_accuracies, label='Training Accuracy', color='blue')\n",
    "    plt.plot(range(1, epoch + 2), test_accuracies, label='Test Accuracy', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Test Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 2: Loss\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(range(1, epoch + 2), train_losses, label='Training Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 3: t-SNE der Outputs\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.scatter(outputs_2d[:, 0], outputs_2d[:, 1], c=labels.cpu().numpy(), cmap='viridis', s=10)\n",
    "    plt.colorbar(label='Class Index')\n",
    "    plt.title('t-SNE of Output Vectors')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "    # Plot 4: Visualisierung der letzten Layer-Gewichte\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(last_fc_weights, cmap='coolwarm', aspect='auto')\n",
    "    plt.colorbar(label='Weight Value')\n",
    "    plt.title('Weights of Last FC Layer')\n",
    "    plt.xlabel('Neurons')\n",
    "    plt.ylabel('Classes')\n",
    "\n",
    "    if switch_epoch is not None and epoch >= switch_epoch + 10:\n",
    "        print(f\"Stopping training after 10 epochs post-switch at epoch {epoch + 1}.\")\n",
    "        plt.savefig(f'model/optim_loop/RMSprop/train_{train_accuracy}_test_{test_accuracy}.png')\n",
    "        break\n",
    "\n",
    "    # Display the updated plot\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "# Save the model's weights\n",
    "torch.save(model.state_dict(), f'model/gute_modell.pth')\n",
    "torch.save(model.state_dict(), f'model/optim_loop/RMSprop/train_{train_accuracy}_test_{test_accuracy}.pth')\n",
    "\n",
    "# Show the final plot after all epochs\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Code from yt \n",
    "(https://www.youtube.com/watch?v=ZBfpkepdZlw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\t\t# load in the data in batches\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # backward propagation and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # at end of epoch check validation loss and acc\n",
    "    with torch.no_grad():\n",
    "      \t# switch model to eval (not train) model\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_val_loss = []\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            total += labels.size(0)\n",
    "            # calculate predictions\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            # calculate actual values\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # calculate the loss\n",
    "            all_val_loss.append(loss_func(outputs, labels).item())\n",
    "        # calculate val-loss\n",
    "        mean_val_loss = sum(all_val_loss) / len(all_val_loss)\n",
    "        # calculate val-accuracy\n",
    "        mean_val_acc = 100 * (correct / total)\n",
    "    print(\n",
    "        'Epoch [{}/{}], Loss: {:.4f}, Val-loss: {:.4f}, Val-acc: {:.1f}%'.format(\n",
    "            epoch+1, num_epochs, loss.item(), mean_val_loss, mean_val_acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # No gradient computation\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the index of the maximum value in the output\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Determine the device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the same device\n",
    "model.to(device)\n",
    "# Calculate accuracy on training data\n",
    "train_accuracy = calculate_accuracy(model, train_loader, device)\n",
    "print(f\"Accuracy on training data: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "print(f\"Accuracy on test data: {test_accuracy:.2f}%\")\n",
    "\n",
    "#torch.save(model.state_dict(), \"model/good_models/99_95_and_95_77/training_99_95_test_95_77.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Berechnet die Accuracy pro Klasse, ohne die Anzahl der Klassen als Eingabe zu benötigen\n",
    "def calculate_class_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Hole die Anzahl der Klassen und die Klassennamen aus dem Dataset\n",
    "    class_names = data_loader.dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Sammle die Richtigkeit der Vorhersagen für jede Klasse\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                class_total[label] += 1\n",
    "                if predicted[i] == labels[i]:\n",
    "                    class_correct[label] += 1\n",
    "    \n",
    "    # Berechne die Accuracy für jede Klasse\n",
    "    class_accuracy = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(num_classes)]\n",
    "    return class_accuracy, class_names\n",
    "\n",
    "# Berechne und plotte die Klassenaccuracy nach den 40 Trainingsepochen\n",
    "class_accuracies, class_names = calculate_class_accuracy(model, test_loader, device)\n",
    "\n",
    "# Plot Histogramm der Klassenaccuracies mit Klassennamen auf der x-Achse\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(range(len(class_names)), class_accuracies, color='skyblue')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy per Class after Training')\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=90)  # Setzt die Klassennamen als x-Achsen-Beschriftungen\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy per Class and save wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Berechnet die Accuracy pro Klasse und speichert falsche Vorhersagen\n",
    "def calculate_class_accuracy_and_misclassifications(model, data_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Hole die Anzahl der Klassen und die Klassennamen aus dem Dataset\n",
    "    class_names = data_loader.dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    misclassified_counts = defaultdict(lambda: [0] * num_classes)  # Zählt Fehlklassifizierungen je Klasse\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Zählt korrekte und fehlerhafte Vorhersagen\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                class_total[label] += 1\n",
    "                if predicted[i] == labels[i]:\n",
    "                    class_correct[label] += 1\n",
    "                else:\n",
    "                    misclassified_counts[label][predicted[i].item()] += 1  # Fehlklassifizierung speichern\n",
    "    \n",
    "    # Berechne die Accuracy für jede Klasse\n",
    "    class_accuracy = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(num_classes)]\n",
    "    return class_accuracy, class_names, misclassified_counts\n",
    "\n",
    "# Berechne Accuracy und Fehlklassifizierungen\n",
    "class_accuracies, class_names, misclassified_counts = calculate_class_accuracy_and_misclassifications(model, test_loader, device)\n",
    "\n",
    "# Erstelle Plots für Klassen mit einer Accuracy < 80%\n",
    "for i, accuracy in enumerate(class_accuracies):\n",
    "    if accuracy < 90:\n",
    "        # Bereite Daten für die Fehlklassifizierungen dieser Klasse auf\n",
    "        misclassified_counts_for_class = misclassified_counts[i]\n",
    "        misclassified_class_names = [class_names[j] for j in range(len(misclassified_counts_for_class)) if misclassified_counts_for_class[j] > 0]\n",
    "        misclassified_class_counts = [misclassified_counts_for_class[j] for j in range(len(misclassified_counts_for_class)) if misclassified_counts_for_class[j] > 0]\n",
    "        \n",
    "        # Plot der Fehlklassifizierungen für die Klasse\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(misclassified_class_names, misclassified_class_counts, color='salmon')\n",
    "        plt.xlabel('Predicted Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(f\"Misclassifications for Class '{class_names[i]}' (Accuracy: {accuracy:.2f}%)\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.grid(axis='y')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to test an old model, you can do this right here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CNN Model Class vor Evaluation. Make sure you replace this with the correct Conv Layers and FC Layers of your trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes, image_size = 100):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=4, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=4, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=4, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer5 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=4, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.max_pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Dynamische Berechnung der FC-Eingabegröße\n",
    "        self.flatten = nn.Flatten()\n",
    "        dummy_input = torch.zeros(batch_size, 3, image_size, image_size)  # Dummy-Eingabe mit typischer Größe (z.B. 224x224)\n",
    "        fc_input_size = self._get_fc_input_size(dummy_input)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc6 = nn.Linear(fc_input_size, 512)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(512, 256)\n",
    "        self.relu7 = nn.ReLU()\n",
    "\n",
    "        self.dropout8 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(256, 128)\n",
    "        self.relu8 = nn.ReLU()\n",
    "\n",
    "        self.fc9 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_fc_input_size(self, dummy_input):\n",
    "        \"\"\"Hilfsfunktion, um die Eingabegröße für die Fully Connected Layers zu berechnen.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = self.conv_layer1(dummy_input)\n",
    "            x = self.relu1(x)\n",
    "            x = self.max_pool1(x)\n",
    "\n",
    "            x = self.conv_layer2(x)\n",
    "            x = self.relu2(x)\n",
    "            x = self.max_pool2(x)\n",
    "\n",
    "            x = self.conv_layer3(x)\n",
    "            x = self.relu3(x)\n",
    "\n",
    "            x = self.conv_layer4(x)\n",
    "            x = self.relu4(x)\n",
    "\n",
    "            x = self.conv_layer5(x)\n",
    "            x = self.relu5(x)\n",
    "            x = self.max_pool5(x)\n",
    "\n",
    "            x = self.flatten(x)  # Flatten the output\n",
    "        return x.size(1)  # Gib die Anzahl der Features zurück\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.max_pool1(out)\n",
    "\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.max_pool2(out)\n",
    "\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.max_pool5(out)\n",
    "\n",
    "        out = self.flatten(out)  # Flatten\n",
    "        out = self.dropout6(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.relu6(out)\n",
    "\n",
    "        out = self.dropout7(out)\n",
    "        out = self.fc7(out)\n",
    "        out = self.relu7(out)\n",
    "\n",
    "        out = self.dropout8(out)\n",
    "        out = self.fc8(out)\n",
    "        out = self.relu8(out)\n",
    "\n",
    "        out = self.fc9(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide now informations such as path and the number of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model\\optim_loop\\SGD\\image_size_100_train_96.64362773852942_test_96.6159265316392.pth'\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Das Modell unter '{model_path}' wurde nicht gefunden.\")\n",
    " \n",
    "# Modell laden\n",
    "trained_model = Net(num_classes=43)\n",
    "trained_model.to(device)\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can test your new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # No gradient computation\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the same device as the model\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the index of the maximum value in the output\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Determine the device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the same device\n",
    "trained_model.to(device)\n",
    "# Calculate accuracy on training data\n",
    "train_accuracy = calculate_accuracy(trained_model, train_transforms_loader, device)\n",
    "print(f\"Accuracy on training data: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = calculate_accuracy(trained_model, test_loader, device)\n",
    "print(f\"Accuracy on test data: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation and Explainable Part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# Select a random or specific image by changing the index\n",
    "rand = 9  # Ändere die Zahl hier, um ein anderes Bild anzuzeigen\n",
    "image = images[rand:rand+1]\n",
    "label = labels[rand]\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "\n",
    "# Display the input image\n",
    "plt.imshow(image[0].permute(1, 2, 0).cpu())  # Bild vom Tensor in NumPy-Format umwandeln\n",
    "plt.title(f'Input Image - Label: {label.item()}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the activations dictionary\n",
    "activations = {}\n",
    "# Ensure hooks are registered (they should be from earlier)\n",
    "# Run the model on the sample image\n",
    "output = trained_model(image)\n",
    "print(activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aktivierungen abrufen\n",
    "act = activations['conv_layer1']\n",
    "print(f\"Shape of conv1 activations: {act.shape}\")\n",
    "\n",
    "# Filter-Anzahl\n",
    "num_filters = act.shape[1]\n",
    "\n",
    "# Dynamische Subplots\n",
    "rows = math.ceil(num_filters / 5)\n",
    "fig, axes = plt.subplots(rows, 5, figsize=(15, rows * 3))\n",
    "\n",
    "for idx in range(num_filters):\n",
    "    row = idx // 5\n",
    "    col = idx % 5\n",
    "    axes[row, col].imshow(act[0, idx].detach().cpu(), cmap='viridis')\n",
    "    axes[row, col].axis('off')\n",
    "    axes[row, col].set_title(f'Filter {idx}')\n",
    "\n",
    "# Unbenutzte Subplots entfernen (falls nötig)\n",
    "for idx in range(num_filters, rows * 5):\n",
    "    row = idx // 5\n",
    "    col = idx % 5\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Maximazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_maximization(model, layer_name, filter_index, input_size=(1, 3, 35, 35), lr=0.1, iterations=30):\n",
    "    device = next(model.parameters()).device  # Gerät des Modells (CPU oder GPU)\n",
    "    \n",
    "    # Initialisierung der Eingabe\n",
    "    input_image = torch.randn(input_size, requires_grad=True, device=device)  # Auf das richtige Gerät legen\n",
    "    \n",
    "    optimizer = optim.Adam([input_image], lr=lr, weight_decay=1e-6)\n",
    "    activations = {}\n",
    "\n",
    "    # Hook-Funktion für die gewünschte Schicht\n",
    "    def hook_function(module, input, output):\n",
    "        activations[layer_name] = output\n",
    "\n",
    "    # Hook registrieren\n",
    "    layer = dict(model.named_modules())[layer_name]\n",
    "    hook = layer.register_forward_hook(hook_function)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        model(input_image)  # Modell auf dem richtigen Gerät ausführen\n",
    "        act = activations[layer_name][0, filter_index]\n",
    "        loss = -torch.mean(act)  # Aktivierung maximieren\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Eingabewerte beschränken\n",
    "        input_image.data = torch.clamp(input_image.data, 0, 1)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Iteration {i+1}/{iterations}, Loss: {-loss.item():.4f}\")\n",
    "\n",
    "    hook.remove()\n",
    "    return input_image.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer1num_filters_relu1 = model.conv_layer1.out_channels\n",
    "am_images_relu1 = []\n",
    "\n",
    "for filter_idx in range(conv_layer1num_filters_relu1):\n",
    "    print(f\"\\nGenerating image for relu1 filter {filter_idx}\")\n",
    "    am_image = activation_maximization(model, 'relu1', filter_idx, input_size=(1, 3, 35, 35), lr=0.1, iterations=30)\n",
    "    am_images_relu1.append(am_image)\n",
    "\n",
    "print(\"\\nCompleted activation maximization for relu1.\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for idx, am_image in enumerate(am_images_relu1[:10]):  # Maximal 10 Bilder anzeigen\n",
    "    row = idx // 5\n",
    "    col = idx % 5\n",
    "    axes[row, col].imshow(am_image.squeeze().permute(1, 2, 0).cpu().numpy())  # RGB-Bild darstellen\n",
    "    axes[row, col].axis('off')\n",
    "    axes[row, col].set_title(f'Filter {idx}')\n",
    "\n",
    "plt.suptitle('Activation Maximization Images for relu1 Filters')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLu 2\n",
    "\n",
    "# Anzahl der Filter in der zweiten Schicht (ReLU2)\n",
    "conv_layer2num_filters_relu2 = model.conv_layer2.out_channels\n",
    "am_images_relu2 = []\n",
    "\n",
    "# Aktivierungsmaximierung für alle Filter der ReLU2-Schicht\n",
    "for filter_idx in range(conv_layer2num_filters_relu2):\n",
    "    print(f\"\\nGenerating image for relu2 filter {filter_idx}\")\n",
    "    am_image = activation_maximization(\n",
    "        model, 'relu2', filter_idx, input_size=(1, 3, 35, 35), lr=0.1, iterations=30\n",
    "    )\n",
    "    am_images_relu2.append(am_image)\n",
    "\n",
    "print(\"\\nCompleted activation maximization for relu2.\")\n",
    "\n",
    "# Darstellung der Ergebnisse\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # Layout für 10 Filter\n",
    "\n",
    "for idx, am_image in enumerate(am_images_relu2[:10]):  # Maximal 10 Bilder anzeigen\n",
    "    row = idx // 5\n",
    "    col = idx % 5\n",
    "    axes[row, col].imshow(am_image.squeeze().permute(1, 2, 0).cpu().numpy())  # RGB-Bild\n",
    "    axes[row, col].axis('off')\n",
    "    axes[row, col].set_title(f'Filter {idx}')\n",
    "\n",
    "plt.suptitle('Activation Maximization Images for relu2 Filters')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dummy-Eingabebild erstellen (RGB-Bild, normalisiert zwischen 0 und 1) und auf das Gerät verschieben\n",
    "img, label = test_dataset[4000]  # Zufälliges Bild (Channels, Height, Width)\n",
    "input_image = img.to(device)  # Die Variable `img` sollte `input_image` zugewiesen werden.\n",
    "\n",
    "# Weiterleitung durch die Schichten bis ReLU2\n",
    "with torch.no_grad():\n",
    "    out_conv1 = model.relu1(model.conv_layer1(input_image))  # Erste Schicht + ReLU\n",
    "    out_pool1 = model.max_pool1(out_conv1)                  # Max-Pooling\n",
    "    out_conv2 = model.relu2(model.conv_layer2(out_pool1))   # Zweite Schicht + ReLU\n",
    "\n",
    "# Eingabebild visualisieren\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img.permute(1, 2, 0).cpu())  # (C, H, W) -> (H, W, C) und auf CPU für die Darstellung\n",
    "plt.axis('off')\n",
    "plt.title(\"Eingabebild\")\n",
    "plt.show()\n",
    "\n",
    "# Ausgabe-Shape der Aktivierung\n",
    "print(\"Shape der Aktivierung nach ReLU2:\", out_conv2.shape)\n",
    "\n",
    "# Aktivierungskarten der ersten 10 Filter visualisieren\n",
    "num_filters = min(10, out_conv2.shape[1])  # Zeige maximal 10 Filter\n",
    "fig, axes = plt.subplots(1, num_filters, figsize=(15, 6))\n",
    "\n",
    "for i in range(num_filters):\n",
    "    activation_map = out_conv2[0, i].cpu().numpy()  # Aktivierung für Filter i\n",
    "    \n",
    "    # Falls die Aktivierungskarten 1D sind, reshape sie zu 2D (H, W)\n",
    "    if activation_map.ndim == 1:\n",
    "        activation_map = activation_map.reshape(35, 35)  # Beispiel für die Größe 35x35 (oder was du benötigst)\n",
    "    \n",
    "    axes[i].imshow(activation_map, cmap='viridis')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Filter {i}')\n",
    "\n",
    "plt.suptitle(\"Aktivierungskarten für ReLU2 (bestimmtes Bild)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import normalize\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def grad_cam(model, input_image, target_class, layer_name):\n",
    "    model.eval()  \n",
    "\n",
    "    # Dictionary to hold gradients and activations\n",
    "    gradients = {}\n",
    "    activations = {}\n",
    "\n",
    "    # Hook to capture gradients\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients[layer_name] = grad_output[0]\n",
    "\n",
    "    # Hook to capture activations\n",
    "    def forward_hook(module, input, output):\n",
    "        activations[layer_name] = output\n",
    "\n",
    "    # Register hooks on the desired layer\n",
    "    layer = dict(model.named_modules())[layer_name]\n",
    "    layer.register_forward_hook(forward_hook)\n",
    "    layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    # Forward pass\n",
    "    input_image = input_image.unsqueeze(0)  # Add batch dimension\n",
    "    input_image = input_image.to(next(model.parameters()).device)  # Move to device\n",
    "    output = model(input_image)\n",
    "\n",
    "    # Backward pass for the target class\n",
    "    model.zero_grad()\n",
    "    target_score = output[0, target_class]\n",
    "    target_score.backward()\n",
    "\n",
    "    # Compute Grad-CAM\n",
    "    grads = gradients[layer_name]  # Gradients from backward pass\n",
    "    acts = activations[layer_name]  # Activations from forward pass\n",
    "    pooled_grads = torch.mean(grads, dim=(2, 3))  # Global average pooling\n",
    "\n",
    "    # Weight activations by pooled gradients\n",
    "    acts = acts * pooled_grads.view(1, -1, 1, 1)  # Apply broadcasting\n",
    "\n",
    "    # Average across the channels\n",
    "    heatmap = torch.mean(acts, dim=1).squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Normalize heatmap\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "# Visualisierung der Grad-CAM\n",
    "def show_grad_cam(image, heatmap, alpha=0.5):\n",
    "    # Normalize image to [0, 1]\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "    # Resize heatmap to match image dimensions using PyTorch\n",
    "    heatmap_tensor = torch.tensor(heatmap).unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "    heatmap_resized = F.interpolate(heatmap_tensor, size=image.shape[:2], mode='bilinear', align_corners=False)\n",
    "    heatmap_resized = heatmap_resized.squeeze().numpy()  # Remove added dims\n",
    "    heatmap_resized = np.uint8(255 * heatmap_resized)  # Scale heatmap to [0, 255]\n",
    "\n",
    "    # Convert heatmap to RGB\n",
    "    heatmap_colored = plt.cm.jet(heatmap_resized)[:, :, :3]  # Convert heatmap to RGB\n",
    "    heatmap_colored = heatmap_colored / np.max(heatmap_colored)  # Normalize heatmap\n",
    "\n",
    "    # Combine heatmap with original image\n",
    "    overlay = alpha * heatmap_colored + (1 - alpha) * image\n",
    "    overlay = overlay / np.max(overlay)  # Normalize overlay to [0, 1]\n",
    "\n",
    "    # Plot the result\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Lade und transformiere ein Bild von einem Pfad\n",
    "def load_image(image_path, input_size=(3, 100, 100)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((input_size[1], input_size[2])),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_image = np.array(image) / 255.0  \n",
    "    image_tensor = transform(image)\n",
    "    return image_tensor, original_image\n",
    "\n",
    "\n",
    "image_path = \"C:/Users/v814u63/Documents/Uni/5. Semester/XAI/images/test_images/lkw_verboten/01374.ppm\"  # Beispielpfad\n",
    "image_tensor, original_image = load_image(image_path)\n",
    "\n",
    "# Zielklasse und Schicht\n",
    "layer_name = \"conv_layer5\" \n",
    "target_class = 0  \n",
    "\n",
    "heatmap = grad_cam(trained_model, image_tensor, target_class, layer_name)\n",
    "show_grad_cam(original_image, heatmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_image import LimeImageExplainer\n",
    "from skimage.segmentation import mark_boundaries, slic\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def transform_image_for_model(image, model_input_size=(3, 35, 35)):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((model_input_size[1], model_input_size[2])),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  \n",
    "\n",
    "def predict_proba(images):\n",
    "    \"\"\"\n",
    "    Wrapper-Funktion für LIME, um Modellvorhersagen für eine Reihe von Bildern zu generieren.\n",
    "    \"\"\"\n",
    "    images_tensor = torch.stack([torch.tensor(image).permute(2, 0, 1) for image in images]).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = trained_model(images_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "explainer = LimeImageExplainer()\n",
    "#Image path\n",
    "image_path = \"GTSRB/Final_Test/Images/100_kmh/00366.ppm\" \n",
    "example_image = Image.open(image_path)\n",
    "transformed_image = transform_image_for_model(example_image).squeeze(0).permute(1, 2, 0).numpy()\n",
    "\n",
    "def custom_segmentation(image):\n",
    "    \"\"\"\n",
    "    Anpassen der Segmentierungsmethode für LIME.\n",
    "    \"\"\"\n",
    "    return slic(image, n_segments=50, compactness=30, start_label=1)\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    transformed_image,\n",
    "    predict_proba,\n",
    "    top_labels=1,\n",
    "    hide_color=0,\n",
    "    num_samples=1000,\n",
    "    segmentation_fn=custom_segmentation \n",
    ")\n",
    "\n",
    "#Vis\n",
    "label_to_explain = explanation.top_labels[0]  \n",
    "temp, mask = explanation.get_image_and_mask(\n",
    "    label=label_to_explain,\n",
    "    positive_only=True,  \n",
    "    hide_rest=False,     \n",
    "    num_features=10,     \n",
    "    min_weight=0.01      \n",
    ")\n",
    "\n",
    "segments = slic(transformed_image, n_segments=50, compactness=30, start_label=1)\n",
    "boundaries_image = mark_boundaries(np.array(example_image) / 255.0, segments)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Originalbild\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(example_image)\n",
    "plt.title(\"Originalbild\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Superpixel-Grenzen \n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(boundaries_image)\n",
    "plt.title(\"Superpixel-Grenzen über Originalbild\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# LIME-\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(mark_boundaries(temp / 255.0, mask))\n",
    "plt.title(f\"LIME-Visualisierung für Klasse {label_to_explain}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Neuron auswählen\n",
    "target_neuron = 28  # Index des gewünschten Neurons (z. B. in der letzten Fully Connected Layer)\n",
    "print(train_dataset.classes[target_neuron])\n",
    "\n",
    "# Zufälliges Startbild erzeugen\n",
    "input_image = torch.randn(1, 3, 100, 100, requires_grad=True, device=device)  # Für 32x32 RGB-Bilder\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam([input_image], lr=0.1)\n",
    "\n",
    "# Normalisierung (optional, falls dein Modell normalisierte Eingaben erwartet)\n",
    "normalize = Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "# Optimierung\n",
    "for step in range(200):  # Anzahl der Schritte für die Optimierung\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Vorwärtsdurchlauf\n",
    "    normalized_input = normalize(input_image)\n",
    "    outputs = model(normalized_input)\n",
    "\n",
    "    # Ziel: Maximierung der Aktivierung des gewählten Neurons\n",
    "    loss = -outputs[0, target_neuron]  # Negative Aktivierung (für Maximierung)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Regularisierung (z. B. Begrenzung der Pixelwerte)\n",
    "    with torch.no_grad():\n",
    "        input_image.clamp_(0, 1)  # Pixelwerte zwischen 0 und 1 halten\n",
    "\n",
    "    # Fortschritt anzeigen\n",
    "    if step % 20 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Visualisierung des optimierten Bildes\n",
    "optimized_image = input_image.detach().cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "plt.imshow(optimized_image)\n",
    "plt.title(f\"Maximale Aktivierung von Neuron {target_neuron}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
