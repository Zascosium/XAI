{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Jupyter Notebooks for implementing the German Traffic Sign Classification CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibt an, ob wir auf einer GPU oder CPU trainieren \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((35, 35)),  \n",
    "    transforms.ToTensor(),\n",
    "    # TODO: Denke das muss man sich nochmal angucken, das hab ausm Internet. Einer in nem video hat da noch mean und std berechnet \n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.9372549..-0.3098039].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc162da9e80>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = ImageFolder(root='GTSRB/Final_Training/Images', transform=transform)\n",
    "\n",
    "# TODO: Hier schauen wegen Label (Testdaten haben keien Label, brauchen sie aber eigentlich oder?)\n",
    "test_dataset = ImageFolder(root='GTSRB/Final_Test', transform=transform)\n",
    "\n",
    "# Die Batchsize ist die Anzahl der Bilder, die auf einmal in das Netzwerk eingespeist werden. \n",
    "# Heißt es werden pro Trainingsschritt 64 Bilder durch das Netzwerk geschickt, dafür der Loss berechnet und dann für diesen Batch gemittelt, \n",
    "# anschließend werden die Parameter auf dem Durchschnittsgradienten aktualisiert.\n",
    "batch_size = 64\n",
    "test_loader = DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n",
    "\n",
    "num_classes = 43\n",
    "# --------- Testing ---------\n",
    "print(test_dataset.targets[2120])\n",
    "img, label = test_dataset[2120]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "#print(img)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model\n",
    "\n",
    "TODO: Über IMG Size sprechen (die meisten nutzen 32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=4, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=4, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=4, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=4, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.max_pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        \n",
    "        self.fc6 = nn.Linear(256, 512) \n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(512, 256)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.fc8 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.max_pool1(out)\n",
    "\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.max_pool2(out)\n",
    "\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.max_pool5(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.dropout6(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.relu6(out)\n",
    "\n",
    "        out = self.dropout7(out)\n",
    "        out = self.fc7(out)\n",
    "        out = self.relu7(out)\n",
    "\n",
    "        out = self.fc8(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes).to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.008\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range (num_epochs) :\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    model.train()\n",
    "    # load in the data in batches\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # forward propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        # backward propagation and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'model/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_val_loss = []\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_val_loss.append(loss_func(outputs, labels).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.80467971459322\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {100 * correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
