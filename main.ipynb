{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Jupyter Notebooks for implementing the German Traffic Sign Classification CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibt an, ob wir auf einer GPU oder CPU trainieren \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((35, 35)),  \n",
    "    transforms.ToTensor(),\n",
    "    # TODO: Denke das muss man sich nochmal angucken, das hab ausm Internet. Einer in nem video hat da noch mean und std berechnet \n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root='GTSRB/Final_Training/Images', transform=transform)\n",
    "\n",
    "# TODO: Hier schauen wegen Label (Testdaten haben keien Label, brauchen sie aber eigentlich oder?)\n",
    "test_dataset = ImageFolder(root='GTSRB/Final_Test', transform=transform)\n",
    "\n",
    "# Die Batchsize ist die Anzahl der Bilder, die auf einmal in das Netzwerk eingespeist werden. \n",
    "# Heißt es werden pro Trainingsschritt 64 Bilder durch das Netzwerk geschickt, dafür der Loss berechnet und dann für diesen Batch gemittelt, \n",
    "# anschließend werden die Parameter auf dem Durchschnittsgradienten aktualisiert.\n",
    "batch_size = 64\n",
    "test_loader = DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size= batch_size, shuffle=True)\n",
    "\n",
    "num_classes = 43\n",
    "# --------- Testing ---------\n",
    "# print(train_dataset.targets[5000])\n",
    "# img, label = train_dataset[5000]\n",
    "# plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model\n",
    "\n",
    "TODO: Über IMG Size sprechen (die meisten nutzen 32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=4, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=4, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=4, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv_layer5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=4, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.max_pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Adjust input dimension based on calculated size\n",
    "        self.fc6 = nn.Linear(256, 512)  # Change according to your calculated values\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(512, 256)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.fc8 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.max_pool1(out)\n",
    "\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.max_pool2(out)\n",
    "\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.max_pool5(out)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.dropout6(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.relu6(out)\n",
    "\n",
    "        out = self.dropout7(out)\n",
    "        out = self.fc7(out)\n",
    "        out = self.relu7(out)\n",
    "\n",
    "        out = self.fc8(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes).to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.008\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range (num_epochs) :\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    model.train()\n",
    "    # load in the data in batches\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # forward propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        # backward propagation and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'model/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_val_loss = []\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_val_loss.append(loss_func(outputs, labels).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
